{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad926a07",
   "metadata": {},
   "source": [
    "Source: https://mira-multiome.readthedocs.io/en/latest/notebooks/tutorial_atlas_integration.html\n",
    "\n",
    "# Atlas-level integration\n",
    "In this tutorial, I will cover some tips and tricks for modeling large collections of single-cells using a scATAC-seq dataset of brain development produced by 10X genomics.\n",
    "\n",
    "One key problem when working with large-scale atlases is it can be hard to know how many topics will best represent the dataset - complex systems could require many tens of topics to capture all of the apparaent heterogeneity. Even though we provide an automated method for determining this, Bayesian search of extremely large ranges is time consuming and inefficient. In this tutorial, I demonstrate how to use gradient descent to estimate the number of topics in a dataset using a Dirichlet Process model.\n",
    "\n",
    "# Preprocessing ATAC-seq data\n",
    "\n",
    "The previous tutorial outlined some best practices for preprocessing scRNA-seq data and selecting genes to model. For scATAC-seq, preprocessing is somewhat less straightforward. The basic pipeline we recommend follows closely with that employed by 10X genomics:\n",
    "\n",
    "1. align ATAC-seq fragments\n",
    "\n",
    "2. Generate fragment file\n",
    "\n",
    "3. Call peaks from fragment file\n",
    "\n",
    "4. Intersect fragments with peaks to generate sparse, near-binary count matrix of size Ncells x Npeaks\n",
    "\n",
    "5. Filter extremely rare peaks (<~30 cells), and non-cell droplets.\n",
    "\n",
    "The 10x pipeline employs an in-house peak caller which does okay. If possible, we recommend re-calling peaks with MACs and re-aggregating fragments. Since highly-variable peaks are hard to identify due to the sparsity of the data, we recommend using all called peaks that are accessible in some reasonable number of cells as features (for example, more than 30 cells).\n",
    "\n",
    "First, import some packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6242dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mira"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be86c80",
   "metadata": {},
   "source": [
    "Since weâ€™re training an accessibility model in this tutorial, we want to make sure we are working on a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0266f746",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2c41b",
   "metadata": {},
   "source": [
    "Now, load some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad414b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mira-env)",
   "language": "python",
   "name": "mira-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
